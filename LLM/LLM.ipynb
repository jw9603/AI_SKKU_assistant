{"cells":[{"cell_type":"markdown","metadata":{"id":"zmtbEd0QHZOX"},"source":["## HuggingFace\n","https://huggingface.co/\n","- Hugging Face is a company that specializes in Natural Language Processing (NLP) and provides a comprehensive set of tools and libraries for working with state-of-the-art models.\n","- One of their most popular contributions is the transformers library, which includes pre-trained models and utilities for training and fine-tuning models like BERT. The library simplifies the process of working with transformer-based models, making them accessible to a broader audience."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2110,"status":"ok","timestamp":1697524628434,"user":{"displayName":"정지원","userId":"16823124283758121408"},"user_tz":-540},"id":"ad8wIHs3RLWE","outputId":"ddddb6aa-a01d-47e2-84c1-ee77763b785f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1697524628434,"user":{"displayName":"정지원","userId":"16823124283758121408"},"user_tz":-540},"id":"QyVLLHE2ROPq","outputId":"32685968-0eff-4cd8-a533-2f35d0ad00f8"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/실습\n"]}],"source":["# google drive에 임의의 폴더를 만들어서 진행합니다. -> 실습\n","%cd ./drive/MyDrive/LLM"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3275,"status":"ok","timestamp":1697524631706,"user":{"displayName":"정지원","userId":"16823124283758121408"},"user_tz":-540},"id":"LdTI2H_JRUsH","outputId":"09bb558f-fe8f-46c6-8023-423fb5a1c377"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch version: 2.0.1+cu118\n","torchvision version: 0.15.2+cu118\n"]}],"source":["import torch\n","import torchvision\n","print(f'torch version: {torch.__version__}')\n","print(f'torchvision version: {torchvision.__version__}')\n"]},{"cell_type":"markdown","metadata":{"id":"jjZus2TaRaI0"},"source":["### Data Preparation : (Korpora)\n","Korpora는 한글 자연어처리를 위한 데이터셋을 손쉽게 로드해주도록 도와주는 오픈소스 파이썬 라이브러리이다.\n","- https://github.com/ko-nlp/Korpora"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":31959,"status":"ok","timestamp":1697524608220,"user":{"displayName":"정지원","userId":"16823124283758121408"},"user_tz":-540},"id":"aWWU3aNNRxYi","outputId":"e194a3ee-18d6-4780-f09c-4cce0597839b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting Korpora==0.2.0rc1\n","  Downloading Korpora-0.2.0rc1-py3-none-any.whl (59 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/59.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting dataclasses>=0.6 (from Korpora==0.2.0rc1)\n","  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n","Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from Korpora==0.2.0rc1) (1.23.5)\n","Requirement already satisfied: tqdm>=4.46.0 in /usr/local/lib/python3.10/dist-packages (from Korpora==0.2.0rc1) (4.66.1)\n","Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from Korpora==0.2.0rc1) (2.31.0)\n","Requirement already satisfied: xlrd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from Korpora==0.2.0rc1) (2.0.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->Korpora==0.2.0rc1) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->Korpora==0.2.0rc1) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->Korpora==0.2.0rc1) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->Korpora==0.2.0rc1) (2023.7.22)\n","Installing collected packages: dataclasses, Korpora\n","Successfully installed Korpora-0.2.0rc1 dataclasses-0.6\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["dataclasses"]}}},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Collecting transformers\n","  Downloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n","Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n","  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers<0.15,>=0.14 (from transformers)\n","  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n","Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n","  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n","Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.34.0\n","Collecting datasets\n","  Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Collecting dill<0.3.8,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.6)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.17.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.4)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, dill, multiprocess, datasets\n","Successfully installed datasets-2.14.5 dill-0.3.7 multiprocess-0.70.15 xxhash-3.4.1\n","Collecting evaluate\n","  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.14.5)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.23.5)\n","Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.15)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.17.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.2)\n","Collecting responses<0.19 (from evaluate)\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.8.6)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.4)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2023.7.22)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.3.post1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n","Installing collected packages: responses, evaluate\n","Successfully installed evaluate-0.4.1 responses-0.18.0\n"]}],"source":["\n","\n","# install 1 : from source\n","# !git clone https://github.com/ko-nlp/Korpora\n","# !python setup.py install\n","\n","# install 2 : using pip\n","!pip install Korpora==0.2.0rc1\n","\n","\n","!pip install transformers\n","!pip install datasets\n","!pip install evaluate"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3456,"status":"ok","timestamp":1697524638451,"user":{"displayName":"정지원","userId":"16823124283758121408"},"user_tz":-540},"id":"JRW0RMXQRW7Y","outputId":"dfa5f420-b120-4027-fbf4-0d4ef2e96773"},"outputs":[{"name":"stdout","output_type":"stream","text":["사용 디바이스: cuda:0\n","\n","    Korpora 는 다른 분들이 연구 목적으로 공유해주신 말뭉치들을\n","    손쉽게 다운로드, 사용할 수 있는 기능만을 제공합니다.\n","\n","    말뭉치들을 공유해 주신 분들에게 감사드리며, 각 말뭉치 별 설명과 라이센스를 공유 드립니다.\n","    해당 말뭉치에 대해 자세히 알고 싶으신 분은 아래의 description 을 참고,\n","    해당 말뭉치를 연구/상용의 목적으로 이용하실 때에는 아래의 라이센스를 참고해 주시기 바랍니다.\n","\n","    # Description\n","    Author : e9t@github\n","    Repository : https://github.com/e9t/nsmc\n","    References : www.lucypark.kr/docs/2015-pyconkr/#39\n","\n","    Naver sentiment movie corpus v1.0\n","    This is a movie review dataset in the Korean language.\n","    Reviews were scraped from Naver Movies.\n","\n","    The dataset construction is based on the method noted in\n","    [Large movie review dataset][^1] from Maas et al., 2011.\n","\n","    [^1]: http://ai.stanford.edu/~amaas/data/sentiment/\n","\n","    # License\n","    CC0 1.0 Universal (CC0 1.0) Public Domain Dedication\n","    Details in https://creativecommons.org/publicdomain/zero/1.0/\n","\n"]},{"name":"stderr","output_type":"stream","text":["[nsmc] download ratings_train.txt: 14.6MB [00:00, 64.8MB/s]                            \n","[nsmc] download ratings_test.txt: 4.90MB [00:00, 31.0MB/s]                           \n"]}],"source":["import os\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","# 한글 자연어 처리 데이터셋\n","from Korpora import Korpora\n","\n","# 토크나이저 관련 경고 무시하기 위하여 설정\n","os.environ[\"TOKENIZERS_PARALLELISM\"] = 'true'\n","\n","# device 지정\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","print(f'사용 디바이스: {device}')\n","\n","corpus = Korpora.load(\"nsmc\")"]},{"cell_type":"markdown","metadata":{"id":"DNtLn9NwSQSp"},"source":["Korpora의 네이버 영화 댓글 데이터셋으로 진행한다\n","- https://github.com/e9t/nsmc"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1351,"status":"ok","timestamp":1697524640519,"user":{"displayName":"정지원","userId":"16823124283758121408"},"user_tz":-540},"id":"FXGWZfLsRqfF","outputId":"0b58be1e-8f1c-4795-bede-895962764faf"},"outputs":[{"name":"stdout","output_type":"stream","text":["train (150000, 3)\n","test (50000, 3)\n"]}],"source":["import pandas as pd\n","\n","train = pd.read_csv('~/Korpora/nsmc/ratings_train.txt', sep='\\t')\n","test = pd.read_csv('~/Korpora/nsmc/ratings_test.txt', sep='\\t')\n","print('train',train.shape)\n","print('test',test.shape)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"executionInfo":{"elapsed":271,"status":"ok","timestamp":1697524752778,"user":{"displayName":"정지원","userId":"16823124283758121408"},"user_tz":-540},"id":"5pNzuySIS7-c","outputId":"e863f31a-8dac-478b-9be6-2e8906675526"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-5910e35d-6a41-40de-90e2-ae09bbe06235\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>document</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>9976970</td>\n","      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3819312</td>\n","      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10265843</td>\n","      <td>너무재밓었다그래서보는것을추천한다</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9045019</td>\n","      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6483659</td>\n","      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5403919</td>\n","      <td>막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>7797314</td>\n","      <td>원작의 긴장감을 제대로 살려내지못했다.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>9443947</td>\n","      <td>별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지..정말 발로해도 그것보단...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>7156791</td>\n","      <td>액션이 없는데도 재미 있는 몇안되는 영화</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>5912145</td>\n","      <td>왜케 평점이 낮은건데? 꽤 볼만한데.. 헐리우드식 화려함에만 너무 길들여져 있나?</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5910e35d-6a41-40de-90e2-ae09bbe06235')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-5910e35d-6a41-40de-90e2-ae09bbe06235 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-5910e35d-6a41-40de-90e2-ae09bbe06235');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-9907bea2-d410-4e50-af93-d9e5b92a13e5\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9907bea2-d410-4e50-af93-d9e5b92a13e5')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-9907bea2-d410-4e50-af93-d9e5b92a13e5 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["         id                                           document  label\n","0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n","1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n","2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n","3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n","4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1\n","5   5403919      막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.      0\n","6   7797314                              원작의 긴장감을 제대로 살려내지못했다.      0\n","7   9443947  별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지..정말 발로해도 그것보단...      0\n","8   7156791                             액션이 없는데도 재미 있는 몇안되는 영화      1\n","9   5912145      왜케 평점이 낮은건데? 꽤 볼만한데.. 헐리우드식 화려함에만 너무 길들여져 있나?      1"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["train.head(10)"]},{"cell_type":"markdown","metadata":{"id":"4rqCvVTyIIYz"},"source":["### 데이터 전처리 및 토큰화"]},{"cell_type":"markdown","metadata":{"id":"Cmr3svjiSvab"},"source":["문장의 길이를 계산하여 [length] column에 담는다."]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":424,"status":"ok","timestamp":1697524762823,"user":{"displayName":"정지원","userId":"16823124283758121408"},"user_tz":-540},"id":"vSatY2MPSeuo"},"outputs":[],"source":["train['length'] = train['document'].apply(lambda x: len(str(x)))\n","test['length'] = test['document'].apply(lambda x: len(str(x)))\n"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1697524767202,"user":{"displayName":"정지원","userId":"16823124283758121408"},"user_tz":-540},"id":"gNDvjxfHS4we","outputId":"79f22f30-b340-49b5-d31e-4a799c7565f4"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-62838a58-c6a6-414f-a202-b85789e6bf39\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>document</th>\n","      <th>label</th>\n","      <th>length</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>9976970</td>\n","      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n","      <td>0</td>\n","      <td>19</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3819312</td>\n","      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n","      <td>1</td>\n","      <td>33</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10265843</td>\n","      <td>너무재밓었다그래서보는것을추천한다</td>\n","      <td>0</td>\n","      <td>17</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9045019</td>\n","      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n","      <td>0</td>\n","      <td>29</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6483659</td>\n","      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n","      <td>1</td>\n","      <td>61</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5403919</td>\n","      <td>막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.</td>\n","      <td>0</td>\n","      <td>45</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>7797314</td>\n","      <td>원작의 긴장감을 제대로 살려내지못했다.</td>\n","      <td>0</td>\n","      <td>21</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>9443947</td>\n","      <td>별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지..정말 발로해도 그것보단...</td>\n","      <td>0</td>\n","      <td>86</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>7156791</td>\n","      <td>액션이 없는데도 재미 있는 몇안되는 영화</td>\n","      <td>1</td>\n","      <td>22</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>5912145</td>\n","      <td>왜케 평점이 낮은건데? 꽤 볼만한데.. 헐리우드식 화려함에만 너무 길들여져 있나?</td>\n","      <td>1</td>\n","      <td>45</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-62838a58-c6a6-414f-a202-b85789e6bf39')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-62838a58-c6a6-414f-a202-b85789e6bf39 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-62838a58-c6a6-414f-a202-b85789e6bf39');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-ead76359-dbd0-4966-8f8c-8dc8a87fabfe\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ead76359-dbd0-4966-8f8c-8dc8a87fabfe')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-ead76359-dbd0-4966-8f8c-8dc8a87fabfe button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["         id                                           document  label  length\n","0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0      19\n","1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1      33\n","2  10265843                                  너무재밓었다그래서보는것을추천한다      0      17\n","3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0      29\n","4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1      61\n","5   5403919      막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.      0      45\n","6   7797314                              원작의 긴장감을 제대로 살려내지못했다.      0      21\n","7   9443947  별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지..정말 발로해도 그것보단...      0      86\n","8   7156791                             액션이 없는데도 재미 있는 몇안되는 영화      1      22\n","9   5912145      왜케 평점이 낮은건데? 꽤 볼만한데.. 헐리우드식 화려함에만 너무 길들여져 있나?      1      45"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["train.head(10)"]},{"cell_type":"markdown","metadata":{"id":"QpOSveVsTGTG"},"source":["문장의 길이가 단어 기준으로 5이상인 문장만 가져온다.\n","\n","- loc : location의 약자로 데이터프레임의 행 또는 칼럼의 label이나 boolean array로 인덱싱하는 방법.\n","    - 칼럼명을 직접 적거나 특정 조건식을 써주어 사람이 읽을 수 있게 데이터에 접근하는 방법\n","    "]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":288,"status":"ok","timestamp":1697524780465,"user":{"displayName":"정지원","userId":"16823124283758121408"},"user_tz":-540},"id":"Iesh_tmqS66L","outputId":"374062b6-751c-42be-dd78-2255bed06758"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-970f2897-a3b0-48d0-a54f-3d91942fcebe\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>document</th>\n","      <th>label</th>\n","      <th>length</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>39064</th>\n","      <td>7991845</td>\n","      <td>군대에서 봤는데 1화부터 정주행 시작하게 만든 드라마.... 6화 남기고 따라잡고 ...</td>\n","      <td>1</td>\n","      <td>140</td>\n","    </tr>\n","    <tr>\n","      <th>90214</th>\n","      <td>10040334</td>\n","      <td>고사 1에서 범인에게 죽었던 배우가 범인이 되어 돌아옴.</td>\n","      <td>0</td>\n","      <td>31</td>\n","    </tr>\n","    <tr>\n","      <th>133461</th>\n","      <td>8281198</td>\n","      <td>장난감으로 전쟁무기를 만든다는내용이 현대사회의 살상무인로봇을 예견하고 만든것같아 섬...</td>\n","      <td>1</td>\n","      <td>57</td>\n","    </tr>\n","    <tr>\n","      <th>84182</th>\n","      <td>8073598</td>\n","      <td>스토리 구성도 괜찮고 영화도 잘찍은 한국영화인데 평점이 너무 낮은거아님??? 9점영...</td>\n","      <td>1</td>\n","      <td>65</td>\n","    </tr>\n","    <tr>\n","      <th>71435</th>\n","      <td>9219448</td>\n","      <td>우연히봤는데넘잼나네요 ㅎㅎ 남자주인공목소리짱짱 기황후때부터완전달달~~ 근데애기엄마가...</td>\n","      <td>1</td>\n","      <td>66</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-970f2897-a3b0-48d0-a54f-3d91942fcebe')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-970f2897-a3b0-48d0-a54f-3d91942fcebe button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-970f2897-a3b0-48d0-a54f-3d91942fcebe');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-523120e5-ac44-4179-806a-1a6f39439d68\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-523120e5-ac44-4179-806a-1a6f39439d68')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-523120e5-ac44-4179-806a-1a6f39439d68 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["              id                                           document  label  \\\n","39064    7991845  군대에서 봤는데 1화부터 정주행 시작하게 만든 드라마.... 6화 남기고 따라잡고 ...      1   \n","90214   10040334                    고사 1에서 범인에게 죽었던 배우가 범인이 되어 돌아옴.      0   \n","133461   8281198  장난감으로 전쟁무기를 만든다는내용이 현대사회의 살상무인로봇을 예견하고 만든것같아 섬...      1   \n","84182    8073598  스토리 구성도 괜찮고 영화도 잘찍은 한국영화인데 평점이 너무 낮은거아님??? 9점영...      1   \n","71435    9219448  우연히봤는데넘잼나네요 ㅎㅎ 남자주인공목소리짱짱 기황후때부터완전달달~~ 근데애기엄마가...      1   \n","\n","        length  \n","39064      140  \n","90214       31  \n","133461      57  \n","84182       65  \n","71435       66  "]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["train = train.loc[train['length'] > 5]\n","\n","# 전체 데이터셋 크기가 커서 1000개의 문장을 샘플링 합니다.\n","train = train.sample(1000)\n","train.head()"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":275,"status":"ok","timestamp":1697524804809,"user":{"displayName":"정지원","userId":"16823124283758121408"},"user_tz":-540},"id":"gi16ANuDTMf5","outputId":"01c8cbcb-fecd-4f03-aca5-b4004cc038b2"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-5daed5d5-88de-4df2-be78-3684a47a46d7\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>document</th>\n","      <th>label</th>\n","      <th>length</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>30205</th>\n","      <td>7459697</td>\n","      <td>쓰레기 더럽게 재미없다..</td>\n","      <td>0</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>13749</th>\n","      <td>8735522</td>\n","      <td>엔딩이 기억에 남는다 평점이 낮은듯하여 별하나 더 단다</td>\n","      <td>1</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>1018831</td>\n","      <td>101, 102.. 103은 못나올것 같다.</td>\n","      <td>0</td>\n","      <td>24</td>\n","    </tr>\n","    <tr>\n","      <th>15541</th>\n","      <td>4409970</td>\n","      <td>정말 재밌는듯!</td>\n","      <td>1</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>2679</th>\n","      <td>9321513</td>\n","      <td>이런 어거지 설정에다 주인공 남녀 둘 발연기 쩐다. 마지막 반전이 주는 교훈이 무색...</td>\n","      <td>0</td>\n","      <td>50</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5daed5d5-88de-4df2-be78-3684a47a46d7')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-5daed5d5-88de-4df2-be78-3684a47a46d7 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-5daed5d5-88de-4df2-be78-3684a47a46d7');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-ce284ff1-2573-4f52-9e81-3310384efe6f\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ce284ff1-2573-4f52-9e81-3310384efe6f')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-ce284ff1-2573-4f52-9e81-3310384efe6f button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["            id                                           document  label  \\\n","30205  7459697                                     쓰레기 더럽게 재미없다..      0   \n","13749  8735522                     엔딩이 기억에 남는다 평점이 낮은듯하여 별하나 더 단다      1   \n","35     1018831                           101, 102.. 103은 못나올것 같다.      0   \n","15541  4409970                                           정말 재밌는듯!      1   \n","2679   9321513  이런 어거지 설정에다 주인공 남녀 둘 발연기 쩐다. 마지막 반전이 주는 교훈이 무색...      0   \n","\n","       length  \n","30205      14  \n","13749      30  \n","35         24  \n","15541       8  \n","2679       50  "]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["test = test.loc[test['length'] > 5]\n","test = test.sample(1000)\n","test.head()"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1697524805827,"user":{"displayName":"정지원","userId":"16823124283758121408"},"user_tz":-540},"id":"3nkFJRoLAptE"},"outputs":[],"source":["MODEL_NAME = 'kykim/bert-kor-base'\n","# MODEL_NAME='kykim/albert-kor-base'"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":633,"status":"ok","timestamp":1697524808937,"user":{"displayName":"정지원","userId":"16823124283758121408"},"user_tz":-540},"id":"hoi65G5XA0AP"},"outputs":[],"source":["import torch\n","from transformers import BertTokenizerFast, AlbertModel\n","from torch.utils.data import Dataset, DataLoader\n","\n","\n","class NaverReviewDataset(Dataset):\n","\n","    def __init__(self, dataframe, tokenizer_pretrained):\n","        # sentence, label 컬럼으로 구성된 데이터프레임 전달\n","        self.data = dataframe\n","        # Huggingface 토크나이저 생성\n","\n","        self.tokenizer = BertTokenizerFast.from_pretrained(tokenizer_pretrained)\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx): # 클래스의 인덱스에 접근할 때 자동으로 호출되는 메서드\n","        # iloc : 행번호로 선택하는 방법\n","        sentence = self.data.iloc[idx]['document']\n","        label = self.data.iloc[idx]['label']\n","\n","        # 토큰화 처리\n","        tokens = self.tokenizer(\n","            sentence,                # 1개 문장\n","            return_tensors='pt',     # 텐서로 반환\n","            truncation=True,         # 잘라내기 적용\n","            padding='max_length',    # 패딩 적용\n","            add_special_tokens=True  # 스페셜 토큰 적용\n","        )\n","\n","        input_ids = tokens['input_ids'].squeeze(0)       # 2D -> 1D : 1,512 -> 512\n","        attention_mask = tokens['attention_mask'].squeeze(0) # 2D -> 1D\n","        token_type_ids = torch.zeros_like(attention_mask)\n","\n","        # input_ids, attention_mask, token_type_ids 이렇게 3가지 요소를 반환하도록 합니다.\n","        # input_ids: 토큰\n","        # attention_mask: 실제 단어가 존재하면 1, 패딩이면 0 (패딩은 0이 아닐 수 있습니다)\n","        # token_type_ids: 문장을 구분하는 id. 단일 문장인 경우에는 전부 0\n","        return {\n","            'input_ids': input_ids,\n","            'attention_mask': attention_mask,\n","            'token_type_ids': token_type_ids,\n","        }, torch.tensor(label)"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":202,"referenced_widgets":["2755c96989b44f02a277f13d8ca3a5aa","c6065877b2d24aa4be69434e6940f4d1","c5c122b96a964f75b292a7c4c846a1bb","8256f11e3ebe4ffe99c7478c82959caf","608c7fc8742846bea2ee2be3d67fb0fb","78773b95a9c743669adcf6c25a951ef1","d9fb19fb79534b82ae4d03585b545126","b41805aca5b5458f9ac142e6ded57755","df218a22daa74c41b56a025f768ad809","e761f89af59c41069781853b569e1989","fd558f05b5c247d58541ad63f76dfec5","2f8c0edc0e144197940513688d95b5a6","4d66f1e0db8142fd9d96e2fbab2ea831","b29958a593c74fbb8a489db535ce7cfa","5b0f8d10ac194d33ac38284b2be7f00f","daafbf7ffbb24384889c3c40027cd994","ea185c234c614b7a988a89a5ac4356a5","96bcffb94a234fb7bd65c4afd4562550","8101f1717afd47e6bc0615c1c4b66815","e53939fa329040408400bfe69890d78b","89a0ed78e3d54cb19d70cc56c886585b","f5dd37b591ba4825bc94fda343428d09","ce5218fa7ff447008ae07b3aab7d8ae4","9ce0da6a8a9e40dba5521d8430753e43","b19f6475a60c43b58bfe4713d9f98593","6189dfd8f4514862874c7f69a02766b4","45393735b8064898bd02c537edee21a4","39578fcb0c1f450eaa99943b360d8e6a","aa8eaef9fddb473b9c607c71da500c60","0755151c65624a4dbe1dfd4f0fea1ec2","f8b3047c9d884937841a1cb757f6e546","a170b0fcbb0b45e5ae57974f66495bba","3d9d6561332e4279b3ea6d45e1d536d5"]},"executionInfo":{"elapsed":867,"status":"ok","timestamp":1697524812470,"user":{"displayName":"정지원","userId":"16823124283758121408"},"user_tz":-540},"id":"L4blIkUlDcpW","outputId":"b2f5f056-f1f7-48f6-d250-50e191893cf4"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2755c96989b44f02a277f13d8ca3a5aa","version_major":2,"version_minor":0},"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/80.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2f8c0edc0e144197940513688d95b5a6","version_major":2,"version_minor":0},"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/344k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ce5218fa7ff447008ae07b3aab7d8ae4","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/725 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["train_loader <torch.utils.data.dataloader.DataLoader object at 0x7d6b9747b490>\n","test_loader <torch.utils.data.dataloader.DataLoader object at 0x7d6b8cdb73a0>\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}],"source":["# 토크나이저 지정\n","tokenizer_pretrained = MODEL_NAME\n","\n","# train, test 데이터셋 생성\n","train_data = NaverReviewDataset(train, tokenizer_pretrained)\n","test_data = NaverReviewDataset(test, tokenizer_pretrained)\n","\n","# DataLoader로 이전에 생성한 Dataset를 지정하여, batch 구성, shuffle, num_workers 등을 설정합니다.\n","train_loader = DataLoader(train_data, batch_size=8, shuffle=True, num_workers=8)\n","test_loader = DataLoader(test_data, batch_size=8, shuffle=False, num_workers=8)\n","# train_loader과 test_loader는 iterator이다.\n","# iterator란 반복을 이용해 어떤 처리를 수행하는 객체를 말한다.\n","print('train_loader',train_loader)\n","print('test_loader',test_loader)"]},{"cell_type":"markdown","metadata":{"id":"vM0stymLDoRj"},"source":["생성된 train_loader로부터 1개의 batch만 꺼내서 값을 확인"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":5610,"status":"ok","timestamp":1697524819912,"user":{"displayName":"정지원","userId":"16823124283758121408"},"user_tz":-540},"id":"4Mle51aPDme8"},"outputs":[],"source":["# 1개의 batch 꺼내기\n","inputs, labels = next(iter(train_loader))\n","\n","# 데이터셋을 device 설정\n","inputs = {k: v.to(device) for k, v in inputs.items()}\n"]},{"cell_type":"markdown","metadata":{"id":"s1uop7jBGAJz"},"source":["- input_ids : 토큰\n","- attention_mask : 실제 단어가 존재하면 1, 패딩이면 0\n","- token_type_ids : 문장을 구분하는 id. 단일 문장인 경우에는 전부 0"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1697524819913,"user":{"displayName":"정지원","userId":"16823124283758121408"},"user_tz":-540},"id":"SqA8PEdbDw9a","outputId":"f9e49f3f-cc9a-451f-d285-9462e63fea9f"},"outputs":[{"data":{"text/plain":["dict_keys(['input_ids', 'attention_mask', 'token_type_ids'])"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["# 생성된 inputs의 key값 출력\n","inputs.keys()"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":441,"status":"ok","timestamp":1697524820352,"user":{"displayName":"정지원","userId":"16823124283758121408"},"user_tz":-540},"id":"3XwOPgCHHCuH","outputId":"d3ed344c-3e84-4092-9432-5addfc0ad02d"},"outputs":[{"data":{"text/plain":["(torch.Size([8, 512]), torch.Size([8, 512]), torch.Size([8, 512]))"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["# key 별 shape 확인\n","inputs['input_ids'].shape, inputs['attention_mask'].shape, inputs['token_type_ids'].shape"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1697524820352,"user":{"displayName":"정지원","userId":"16823124283758121408"},"user_tz":-540},"id":"5tmLwOwqHzyt","outputId":"5feafcc6-8529-4802-ebb8-b7429071fdb8"},"outputs":[{"data":{"text/plain":["BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"directionality\": \"bidi\",\n","  \"embedding_size\": 768,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.34.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 42000\n","}"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["from transformers import BertConfig\n","\n","config = BertConfig.from_pretrained(MODEL_NAME)\n","config"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1697524820352,"user":{"displayName":"정지원","userId":"16823124283758121408"},"user_tz":-540},"id":"Upl8X1qYH37M","outputId":"bc155bb1-85cf-4a82-8f7a-e33502382e88"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([0, 0, 1, 1, 0, 1, 0, 1])\n"]}],"source":["# label 출력\n","print(labels)"]},{"cell_type":"markdown","metadata":{"id":"gQE_XOrqIMzn"},"source":["### Pretrained Model 호출"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":761,"referenced_widgets":["b31da87ab7224eafa4a8ba62b9bd90ae","65fca187c6ef4503a827b0ea6344cffa","432a9751054e474d8c03e64cc0756c97","57f6af2ce575418da93bae66dd3ecd84","0acc3c745a4941b5bfde1e8c5ef12598","476ae4fcd59048129af937996868d493","90165400d18b49bfb1d800bd7f12ef39","03a51ba983f245afb62c6cb6cad3bf1b","b33721ae7fa54593a28df374199fb92a","a1b6cfcc41104b3a8b6464adcca4d728","e5297599bdb94a7996308cc4388ad954"]},"executionInfo":{"elapsed":4432,"status":"ok","timestamp":1697524824782,"user":{"displayName":"정지원","userId":"16823124283758121408"},"user_tz":-540},"id":"C99eRGVWIC2T","outputId":"d76f1d3b-16fc-4ff2-d9cb-54071093197b"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b31da87ab7224eafa4a8ba62b9bd90ae","version_major":2,"version_minor":0},"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/476M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["BertModel(\n","  (embeddings): BertEmbeddings(\n","    (word_embeddings): Embedding(42000, 768, padding_idx=0)\n","    (position_embeddings): Embedding(512, 768)\n","    (token_type_embeddings): Embedding(2, 768)\n","    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (encoder): BertEncoder(\n","    (layer): ModuleList(\n","      (0-11): 12 x BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (pooler): BertPooler(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (activation): Tanh()\n","  )\n",")"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["from transformers import BertModel\n","from transformers import AlbertModel\n","\n","# 모델 생성\n","model = BertModel.from_pretrained(MODEL_NAME).to(device)\n","model"]},{"cell_type":"markdown","metadata":{"id":"Ygxjo49nJb5u"},"source":["결과를 output 에 담은 후 key를 출력해 보면 'last_hidden_state' 와 'pooler_output'이렇게 2개가 출력된다.다.\n","\n","- last_hidden_state는 배치의 각 시퀀스에서 각 토큰에 대한 숨겨진 표현을 포함한다. 따라서 크기는 (batch_size, seq_len, hidden_size)입니다.\n","\n","- pooler_output은 배치의 각 시퀀스의 “표현”을 포함하며 크기(batch_size, hidden_size)입니다. 기본적으로 하는 일은 배치(hidden_size 크기의 벡터)에서 각 시퀀스의 [CLS] 토큰의 숨겨진 표현을 가져온 다음 BertPooler를 통해 실행하는 것입니다. 이것은 선형 레이어와 Tanh 활성화 함수로 구성됩니다."]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3001,"status":"ok","timestamp":1697524827772,"user":{"displayName":"정지원","userId":"16823124283758121408"},"user_tz":-540},"id":"MhTk6_dXIyYE","outputId":"42bd1167-032b-4fb9-bcac-6a231b8f9095"},"outputs":[{"data":{"text/plain":["odict_keys(['last_hidden_state', 'pooler_output'])"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["output = model(**inputs)\n","output.keys()"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1697524827772,"user":{"displayName":"정지원","userId":"16823124283758121408"},"user_tz":-540},"id":"UWmlWh1VJYAR","outputId":"d490637f-d5a5-427b-ed01-5eb0921eec52"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([8, 512, 768])\n","torch.Size([8, 768])\n"]}],"source":["print(output['last_hidden_state'].shape)\n","print(output['pooler_output'].shape)\n"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1697524827772,"user":{"displayName":"정지원","userId":"16823124283758121408"},"user_tz":-540},"id":"BMcexTTUJw5I","outputId":"086511fc-5183-4418-cf21-b2cdefa94bee"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[ 0.2926, -0.3248,  0.2659,  ..., -0.0742, -0.4780,  0.3885],\n","        [ 0.4464, -0.1872,  0.6020,  ...,  0.0545, -0.4779,  0.5408],\n","        [-2.1677, -0.9836, -0.5510,  ..., -0.5291, -0.8370, -0.5792],\n","        ...,\n","        [ 0.4106,  0.1202,  0.4509,  ...,  0.4587, -0.8346,  0.7352],\n","        [ 0.5539, -0.0649,  0.2421,  ..., -0.0849, -1.2561,  0.6370],\n","        [-0.6978,  0.6750, -0.0487,  ..., -1.2351, -0.8963,  0.0999]],\n","       device='cuda:0', grad_fn=<SliceBackward0>)\n"]}],"source":["print(output['last_hidden_state'][:,0,:])\n"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1697524827772,"user":{"displayName":"정지원","userId":"16823124283758121408"},"user_tz":-540},"id":"QxWs7ktCKfYM","outputId":"c81d1fdd-653f-4491-b12b-a1e61e8bffaa"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[-0.8815,  0.4257, -0.9078,  ...,  0.0422, -0.1953,  0.6971],\n","        [-0.8427,  0.4335, -0.7918,  ...,  0.8716,  0.0607,  0.6371],\n","        [ 0.5967,  0.1638, -0.9027,  ..., -0.3862,  0.6422, -0.4995],\n","        ...,\n","        [-0.8711,  0.4038, -0.8682,  ...,  0.3048,  0.3644,  0.3480],\n","        [-0.6790,  0.7396, -0.9539,  ...,  0.0763,  0.4840,  0.8659],\n","        [-0.6333,  0.7559, -0.9989,  ...,  0.3955,  0.8927,  0.5803]],\n","       device='cuda:0', grad_fn=<TanhBackward0>)\n"]}],"source":["print(output['pooler_output'])"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1697524827772,"user":{"displayName":"정지원","userId":"16823124283758121408"},"user_tz":-540},"id":"WKRlfPKmKjFc","outputId":"09c9a85d-de9c-4d8e-b241-7cc2014ab393"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([8, 2])\n","tensor([[-0.0302, -0.5379],\n","        [-0.1904, -0.6359],\n","        [ 0.1097, -0.2958],\n","        [ 0.0457, -0.3866],\n","        [ 0.4618, -0.7528],\n","        [-0.4076, -0.4738],\n","        [-0.2375, -0.3293],\n","        [ 0.1295, -0.9238]], device='cuda:0', grad_fn=<AddmmBackward0>)\n","tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n"]}],"source":["fc = nn.Linear(768, 2)\n","fc.to(device)\n","fc_output = fc(output['last_hidden_state'][:, 0, :])\n","print(fc_output.shape)\n","print(fc_output)\n","print(fc_output.argmax(dim=1))"]},{"cell_type":"markdown","metadata":{"id":"fG-Lz16TK-GK"},"source":["### Let's fine-tuning"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1697524827772,"user":{"displayName":"정지원","userId":"16823124283758121408"},"user_tz":-540},"id":"qCnKIY9HKwXV"},"outputs":[],"source":["class FineTuningBertModel(nn.Module):\n","    def __init__(self, bert_pretrained, dropout_rate=0.5):\n","        # 부모클래스 초기화\n","        super().__init__()\n","        # 사전학습 모델 지정\n","        self.bert = BertModel.from_pretrained(bert_pretrained)\n","\n","        # dropout 설정\n","        self.dropout = nn.Dropout(p=dropout_rate)\n","        # 최종 출력층 정의\n","        self.fc = nn.Linear(768, 2)\n","\n","    def forward(self, input_ids, attention_mask, token_type_ids):\n","        # 입력을 pre-trained bert model 로 대입\n","        output = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n","        # 결과의 last_hidden_state 가져옴\n","        last_hidden_state = output['last_hidden_state']\n","        # last_hidden_state[:, 0, :]는 [CLS] 토큰을 가져옴\n","        x = self.dropout(last_hidden_state[:, 0, :])\n","        # FC 을 거쳐 최종 출력\n","        x = self.fc(x)\n","        return x"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2521,"status":"ok","timestamp":1697524830291,"user":{"displayName":"정지원","userId":"16823124283758121408"},"user_tz":-540},"id":"4m5Rq9rGLKQx","outputId":"88d65b7c-5560-4a5e-afe4-7b6ac5537711"},"outputs":[{"data":{"text/plain":["FineTuningBertModel(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(42000, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.5, inplace=False)\n","  (fc): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["BERT_model = FineTuningBertModel(MODEL_NAME)\n","BERT_model.to(device)"]},{"cell_type":"markdown","metadata":{"id":"3hWvSod5LV2z"},"source":["Loss & Optimizer"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1697524830291,"user":{"displayName":"정지원","userId":"16823124283758121408"},"user_tz":-540},"id":"1S4GYGbWLQDD"},"outputs":[],"source":["# loss 정의: CrossEntropyLoss\n","loss_fn = nn.CrossEntropyLoss()\n","\n","# 옵티마이저 정의: bert.paramters()와 learning_rate 설정\n","optimizer = optim.Adam(BERT_model.parameters(), lr=1e-5)"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":260,"status":"ok","timestamp":1697524832624,"user":{"displayName":"정지원","userId":"16823124283758121408"},"user_tz":-540},"id":"MTJCZ0GMLcBW"},"outputs":[],"source":["from tqdm import tqdm  # Progress Bar 출력\n","\n","def model_train(model, data_loader, loss_fn, optimizer, device):\n","    # 모델을 훈련모드로 설정합니다. training mode 일 때 Gradient 가 업데이트 됩니다. 반드시 train()으로 모드 변경을 해야 합니다.\n","    model.train()\n","\n","    # loss와 accuracy 계산을 위한 임시 변수 입니다. 0으로 초기화합니다.\n","    running_loss = 0\n","    corr = 0\n","    counts = 0\n","\n","    # 예쁘게 Progress Bar를 출력하면서 훈련 상태를 모니터링 하기 위하여 tqdm으로 래핑합니다.\n","    prograss_bar = tqdm(data_loader, unit='batch', total=len(data_loader), mininterval=1)\n","\n","    # mini-batch 학습을 시작합니다.\n","    for idx, (inputs, labels) in enumerate(prograss_bar):\n","        # inputs, label 데이터를 device 에 올립니다. (cuda:0 혹은 cpu)\n","        inputs = {k:v.to(device) for k, v in inputs.items()}\n","        labels = labels.to(device)\n","\n","        # 누적 Gradient를 초기화 합니다.\n","        optimizer.zero_grad()\n","\n","        # Forward Propagation을 진행하여 결과를 얻습니다.\n","        output = model(**inputs)\n","\n","        # 손실함수에 output, label 값을 대입하여 손실을 계산합니다.\n","        loss = loss_fn(output, labels)\n","\n","        # 오차역전파(Back Propagation)을 진행하여 미분 값을 계산합니다.\n","        loss.backward()\n","\n","        # 계산된 Gradient를 업데이트 합니다.\n","        optimizer.step()\n","\n","        # output의 max(dim=1)은 max probability와 max index를 반환합니다.\n","        # max probability는 무시하고, max index는 pred에 저장하여 label 값과 대조하여 정확도를 도출합니다.\n","        # print('output',output.shape) # (8, 2)\n","        _, index = output.max(dim=1)\n","\n","        # pred.eq(lbl).sum() 은 정확히 맞춘 label의 합계를 계산합니다. item()은 tensor에서 값을 추출합니다.\n","        # 합계는 corr 변수에 누적합니다.\n","        corr += index.eq(labels).sum().item()\n","        counts += len(labels)\n","\n","        # loss 값은 1개 배치의 평균 손실(loss) 입니다. labels.size(0)은 배치사이즈(batch size) 입니다.\n","        # loss 와 labels.size(0)를 곱하면 1개 배치의 전체 loss가 계산됩니다.\n","        # 이를 누적한 뒤 Epoch 종료시 전체 데이터셋의 개수로 나누어 평균 loss를 산출합니다.\n","        running_loss += loss.item() * labels.size(0)\n","\n","        # 프로그레스바에 학습 상황 업데이트\n","        prograss_bar.set_description(f\"training loss: {running_loss/(idx+1):.5f}, training accuracy: {corr / counts:.5f}\")\n","        # 배치당 training loss,\n","\n","    # 누적된 정답수를 전체 개수로 나누어 주면 정확도가 산출됩니다.\n","    acc = corr / len(data_loader.dataset)\n","\n","    # 평균 손실(loss)과 정확도를 반환합니다.\n","    # train_loss, train_acc\n","    return running_loss / len(data_loader.dataset), acc"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":259,"status":"ok","timestamp":1697524838197,"user":{"displayName":"정지원","userId":"16823124283758121408"},"user_tz":-540},"id":"YolA7jPlMCnp"},"outputs":[],"source":["def model_evaluate(model, data_loader, loss_fn, device):\n","    # model.eval()은 모델을 평가모드로 설정을 바꾸어 줍니다.\n","    # dropout과 같은 layer의 역할 변경을 위하여 evaluation 진행시 꼭 필요한 절차 입니다.\n","    model.eval()\n","\n","    # Gradient가 업데이트 되는 것을 방지 하기 위하여 반드시 필요합니다.\n","    with torch.no_grad():\n","        # loss와 accuracy 계산을 위한 임시 변수 입니다. 0으로 초기화합니다.\n","        corr = 0\n","        running_loss = 0\n","\n","        # 배치별 evaluation을 진행합니다.\n","        for inputs, labels in data_loader:\n","            # inputs, label 데이터를 device 에 올립니다. (cuda:0 혹은 cpu)\n","            inputs = {k:v.to(device) for k, v in inputs.items()}\n","            labels = labels.to(device)\n","\n","            # 모델에 Forward Propagation을 하여 결과를 도출합니다.\n","            output = model(**inputs) # (8,2)\n","\n","            # output의 max(dim=1)은 max probability와 max index를 반환합니다.\n","            # max probability는 무시하고, max index는 pred에 저장하여 label 값과 대조하여 정확도를 도출합니다.\n","            _, index = output.max(dim=1)\n","\n","            # idx.eq(lbl).sum() 은 정확히 맞춘 label의 합계를 계산합니다. item()은 tensor에서 값을 추출합니다.\n","            # 합계는 corr 변수에 누적합니다.\n","            corr += torch.sum(index.eq(labels)).item()\n","\n","            # loss 값은 1개 배치의 평균 손실(loss) 입니다. img.size(0)은 배치사이즈(batch size) 입니다.\n","            # loss 와 img.size(0)를 곱하면 1개 배치의 전체 loss가 계산됩니다.\n","            # 이를 누적한 뒤 Epoch 종료시 전체 데이터셋의 개수로 나누어 평균 loss를 산출합니다.\n","            running_loss += loss_fn(output, labels).item() * labels.size(0)\n","\n","        # validation 정확도를 계산합니다.\n","        # 누적한 정답숫자를 전체 데이터셋의 숫자로 나누어 최종 accuracy를 산출합니다.\n","        acc = corr / len(data_loader.dataset)\n","\n","        # 결과를 반환합니다.\n","        # val_loss, val_acc\n","        return running_loss / len(data_loader.dataset), acc"]},{"cell_type":"markdown","metadata":{"id":"2Y3OPCRpHvI-"},"source":["Training Loop"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1218272,"status":"ok","timestamp":1697526062719,"user":{"displayName":"정지원","userId":"16823124283758121408"},"user_tz":-540},"id":"9o9DLKYWMMm0","outputId":"b3533070-c6f7-4c14-de3c-5a4bdfc37648"},"outputs":[{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/125 [00:00<?, ?batch/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","training loss: 5.52544, training accuracy: 0.61400: 100%|██████████| 125/125 [01:25<00:00,  1.46batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["[INFO] val_loss has been improved from inf to 0.39890. Saving Model!\n","epoch 01, loss: 0.69068, acc: 0.61400, val_loss: 0.39890, val_accuracy: 0.83200\n"]},{"name":"stderr","output_type":"stream","text":["training loss: 3.14927, training accuracy: 0.85100: 100%|██████████| 125/125 [01:29<00:00,  1.39batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["[INFO] val_loss has been improved from 0.39890 to 0.36064. Saving Model!\n","epoch 02, loss: 0.39366, acc: 0.85100, val_loss: 0.36064, val_accuracy: 0.85200\n"]},{"name":"stderr","output_type":"stream","text":["training loss: 2.15012, training accuracy: 0.90200: 100%|██████████| 125/125 [01:29<00:00,  1.39batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch 03, loss: 0.26877, acc: 0.90200, val_loss: 0.37604, val_accuracy: 0.85900\n"]},{"name":"stderr","output_type":"stream","text":["training loss: 1.40850, training accuracy: 0.93600: 100%|██████████| 125/125 [01:30<00:00,  1.38batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch 04, loss: 0.17606, acc: 0.93600, val_loss: 0.39192, val_accuracy: 0.86200\n"]},{"name":"stderr","output_type":"stream","text":["training loss: 0.58425, training accuracy: 0.97600: 100%|██████████| 125/125 [01:29<00:00,  1.39batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch 05, loss: 0.07303, acc: 0.97600, val_loss: 0.48222, val_accuracy: 0.85400\n"]},{"name":"stderr","output_type":"stream","text":["training loss: 0.38245, training accuracy: 0.98700: 100%|██████████| 125/125 [01:30<00:00,  1.39batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch 06, loss: 0.04781, acc: 0.98700, val_loss: 0.53274, val_accuracy: 0.85400\n"]},{"name":"stderr","output_type":"stream","text":["training loss: 0.27152, training accuracy: 0.99300: 100%|██████████| 125/125 [01:29<00:00,  1.39batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch 07, loss: 0.03394, acc: 0.99300, val_loss: 0.51526, val_accuracy: 0.86400\n"]},{"name":"stderr","output_type":"stream","text":["training loss: 0.15668, training accuracy: 0.99500: 100%|██████████| 125/125 [01:30<00:00,  1.39batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch 08, loss: 0.01959, acc: 0.99500, val_loss: 0.65845, val_accuracy: 0.86500\n"]},{"name":"stderr","output_type":"stream","text":["training loss: 0.28018, training accuracy: 0.99000: 100%|██████████| 125/125 [01:30<00:00,  1.39batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch 09, loss: 0.03502, acc: 0.99000, val_loss: 0.73953, val_accuracy: 0.84500\n"]},{"name":"stderr","output_type":"stream","text":["training loss: 0.37462, training accuracy: 0.98500: 100%|██████████| 125/125 [01:30<00:00,  1.38batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch 10, loss: 0.04683, acc: 0.98500, val_loss: 0.60997, val_accuracy: 0.85500\n"]}],"source":["# 최대 Epoch을 지정합니다.\n","num_epochs = 10\n","\n","# checkpoint로 저장할 모델의 이름을 정의 합니다.\n","model_name = 'bert-kor-base'\n","\n","min_loss = np.inf\n","\n","# Epoch 별 훈련 및 검증을 수행합니다.\n","for epoch in range(num_epochs):\n","    # Model Training\n","    # 훈련 손실과 정확도를 반환 받습니다.\n","    train_loss, train_acc = model_train(BERT_model, train_loader, loss_fn, optimizer, device)\n","\n","    # 검증 손실과 검증 정확도를 반환 받습니다.\n","    val_loss, val_acc = model_evaluate(BERT_model, test_loader, loss_fn, device)\n","\n","    # val_loss 가 개선되었다면 min_loss를 갱신하고 model의 가중치(weights)를 저장합니다.\n","    if val_loss < min_loss:\n","        print(f'[INFO] val_loss has been improved from {min_loss:.5f} to {val_loss:.5f}. Saving Model!')\n","        min_loss = val_loss\n","        torch.save(BERT_model.state_dict(), f'{model_name}.pth')\n","\n","    # Epoch 별 결과를 출력합니다.\n","    print(f'epoch {epoch+1:02d}, loss: {train_loss:.5f}, acc: {train_acc:.5f}, val_loss: {val_loss:.5f}, val_accuracy: {val_acc:.5f}')"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1204,"status":"ok","timestamp":1697526163691,"user":{"displayName":"정지원","userId":"16823124283758121408"},"user_tz":-540},"id":"oehuPvDoMQ2_","outputId":"de042f33-44a4-4732-c5bd-3c3bebae8d91"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["# 저장한 state_dict를 로드 합니다.\n","BERT_model.load_state_dict(torch.load(f'{model_name}.pth'))"]},{"cell_type":"markdown","metadata":{"id":"Xviio9MzRAa2"},"source":["### Inference"]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1697526165615,"user":{"displayName":"정지원","userId":"16823124283758121408"},"user_tz":-540},"id":"AzN3bjTHRABf"},"outputs":[],"source":["class Predictor():\n","    def __init__(self, model, tokenizer, labels: dict):\n","        self.model = model\n","        self.tokenizer = tokenizer\n","        self.labels = labels\n","\n","    def predict(self, sentence):\n","        # 토큰화 처리\n","        tokens = self.tokenizer(\n","            sentence,                # 1개 문장\n","            return_tensors='pt',     # 텐서로 반환\n","            truncation=True,         # 잘라내기 적용\n","            padding='max_length',    # 패딩 적용\n","            add_special_tokens=True  # 스페셜 토큰 적용\n","        )\n","        tokens.to(device)\n","        prediction = self.model(**tokens) # (1, 2)\n","\n","        prediction = F.softmax(prediction, dim=1) # (1,2)\n","\n","        output = prediction.argmax(dim=1).item()\n","\n","        prob, result = prediction.max(dim=1)[0].item(), self.labels[output]\n","        print(f'[{result}]\\n확률은: {prob*100:.3f}% 입니다.')"]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":302,"status":"ok","timestamp":1697526166337,"user":{"displayName":"정지원","userId":"16823124283758121408"},"user_tz":-540},"id":"M2ITBcQiRZIf"},"outputs":[],"source":["# Huggingface 토크나이저 생성\n","tokenizer = BertTokenizerFast.from_pretrained(MODEL_NAME)\n","\n","labels = {\n","    0: '부정 리뷰 입니다.',\n","    1: '긍정 리뷰 입니다.'\n","}\n","\n","# Predictor 인스턴스를 생성합니다.\n","predictor = Predictor(BERT_model, tokenizer, labels)"]},{"cell_type":"code","execution_count":38,"metadata":{"executionInfo":{"elapsed":427,"status":"ok","timestamp":1697526169506,"user":{"displayName":"정지원","userId":"16823124283758121408"},"user_tz":-540},"id":"qH6S8JHxRjDQ"},"outputs":[],"source":["# 사용자 입력에 대하여 예측 후 출력을 낼 수 있는 간단한 함수를 생성합니다.\n","def predict_sentence(predictor):\n","    input_sentence = input('문장을 입력해 주세요: ')\n","    predictor.predict(input_sentence)\n"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10290,"status":"ok","timestamp":1697526180946,"user":{"displayName":"정지원","userId":"16823124283758121408"},"user_tz":-540},"id":"UeW9BMRMVEI9","outputId":"ccaa973e-a6d8-4ad1-b959-e707032c1001"},"outputs":[{"name":"stdout","output_type":"stream","text":["문장을 입력해 주세요: 난 이 영화가 별로야\n","[부정 리뷰 입니다.]\n","확률은: 76.296% 입니다.\n"]}],"source":["# 부정 리뷰 입력 예시\n","predict_sentence(predictor)"]},{"cell_type":"markdown","metadata":{"id":"ZxP3-9bIZECA"},"source":["### 실습\n","1. 빈칸을 채우시오.\n","2. 임의의 5문장의 결과를 스크린샷으로 저장해서 올리시오."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VEwJQgL-benX"},"outputs":[],"source":["import pandas as pd\n","\n","train = pd.read_csv('~/Korpora/nsmc/ratings_train.txt', sep='\\t')\n","test = pd.read_csv('~/Korpora/nsmc/ratings_test.txt', sep='\\t')\n","print('train',train.shape)\n","print('test',test.shape)\n","train['length'] = train['document'].apply(lambda x: len(str(x)))\n","test['length'] = test['document'].apply(lambda x: len(str(x)))\n","\n","\n","train = train.loc[train['length'] > 5]\n","train = train.sample(1000)\n","test = test.loc[test['length'] > 5]\n","test = test.sample(1000)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GYJBuXjMb8Oo"},"outputs":[],"source":["import torch\n","from transformers import BertTokenizerFast, AlbertModel\n","from torch.utils.data import Dataset, DataLoader\n","\n","\n","class NaverReviewDataset(Dataset):\n","\n","    def __init__(self, dataframe, tokenizer_pretrained):\n","        # sentence, label 컬럼으로 구성된 데이터프레임 전달\n","        self.data = dataframe\n","        # Huggingface 토크나이저 생성\n","\n","        self.tokenizer = BertTokenizerFast.from_pretrained(tokenizer_pretrained)\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx): # 클래스의 인덱스에 접근할 때 자동으로 호출되는 메서드\n","        # iloc : 행번호로 선택하는 방법\n","        sentence = self.data.iloc[idx]['document']\n","        label = self.data.iloc[idx]['label']\n","\n","        # 토큰화 처리\n","        tokens = self.tokenizer(\n","            sentence,                # 1개 문장\n","            return_tensors='pt',     # 텐서로 반환\n","            truncation=True,         # 잘라내기 적용\n","            padding='max_length',    # 패딩 적용\n","            add_special_tokens=True  # 스페셜 토큰 적용\n","        )\n","\n","        input_ids = tokens['input_ids'].squeeze(0)       # 2D -> 1D : 1,512 -> 512\n","        attention_mask = tokens['attention_mask'].squeeze(0) # 2D -> 1D\n","        token_type_ids = torch.zeros_like(attention_mask)\n","\n","        # input_ids, attention_mask, token_type_ids 이렇게 3가지 요소를 반환하도록 합니다.\n","        # input_ids: 토큰\n","        # attention_mask: 실제 단어가 존재하면 1, 패딩이면 0 (패딩은 0이 아닐 수 있습니다)\n","        # token_type_ids: 문장을 구분하는 id. 단일 문장인 경우에는 전부 0\n","        return {\n","            'input_ids': input_ids,\n","            'attention_mask': attention_mask,\n","            'token_type_ids': token_type_ids,\n","        }, torch.tensor(label)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CuLtNrJVVEpz"},"outputs":[],"source":["MODEL_NAME='kykim/albert-kor-base'\n","from transformers import AlbertModel\n","# 토크나이저 지정\n","tokenizer_pretrained = MODEL_NAME\n","\n","# train, test 데이터셋 생성\n","train_data = NaverReviewDataset(train, tokenizer_pretrained)\n","test_data = NaverReviewDataset(test, tokenizer_pretrained)\n","\n","# DataLoader로 이전에 생성한 Dataset를 지정하여, batch 구성, shuffle, num_workers 등을 설정합니다.\n","train_loader = DataLoader(train_data, batch_size=8, shuffle=True, num_workers=8)\n","test_loader = DataLoader(test_data, batch_size=8, shuffle=False, num_workers=8)\n","# train_loader과 test_loader는 iterator이다.\n","# iterator란 반복을 이용해 어떤 처리를 수행하는 객체를 말한다.\n","print('train_loader',train_loader)\n","print('test_loader',test_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0nLPaFVVZWAf"},"outputs":[],"source":["class FineTuningBertModel(nn.Module):\n","    def __init__(self, bert_pretrained, dropout_rate=0.5):\n","        # 부모클래스 초기화\n","        super().__init__()\n","        # 1. 사전학습 모델 지정\n","        ###################################################\n","\n","        ###################################################\n","        # 2. dropout 설정\n","        ###################################################\n","\n","        ###################################################\n","        # 3. 최종 출력층 정의\n","        ###################################################\n","\n","        ###################################################\n","\n","    def forward(self, input_ids, attention_mask, token_type_ids):\n","        # 입력을 pre-trained bert model 로 대입\n","        output = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n","        # 4. 결과의 last_hidden_state 가져옴\n","        ##############################################\n","\n","        ##############################################\n","        # 5.[CLS] 토큰을 가져옴\n","        ##############################################\n","\n","        ##############################################\n","        # FC 을 거쳐 최종 출력\n","        x = self.fc(x)\n","        return x\n","\n","albert_model = FineTuningBertModel(MODEL_NAME)\n","albert_model.to(device)\n","\n","# loss 정의: CrossEntropyLoss\n","loss_fn = nn.CrossEntropyLoss()\n","\n","# 옵티마이저 정의: bert.paramters()와 learning_rate 설정\n","optimizer = optim.Adam(BERT_model.parameters(), lr=1e-5)\n","\n","from tqdm import tqdm  # Progress Bar 출력\n","\n","def model_train(model, data_loader, loss_fn, optimizer, device):\n","    # 모델을 훈련모드로 설정합니다. training mode 일 때 Gradient 가 업데이트 됩니다. 반드시 train()으로 모드 변경을 해야 합니다.\n","    model.train()\n","\n","    # loss와 accuracy 계산을 위한 임시 변수 입니다. 0으로 초기화합니다.\n","    running_loss = 0\n","    corr = 0\n","    counts = 0\n","\n","    # 예쁘게 Progress Bar를 출력하면서 훈련 상태를 모니터링 하기 위하여 tqdm으로 래핑합니다.\n","    prograss_bar = tqdm(data_loader, unit='batch', total=len(data_loader), mininterval=1)\n","\n","    # mini-batch 학습을 시작합니다.\n","    for idx, (inputs, labels) in enumerate(prograss_bar):\n","        # inputs, label 데이터를 device 에 올립니다. (cuda:0 혹은 cpu)\n","        inputs = {k:v.to(device) for k, v in inputs.items()}\n","        labels = labels.to(device)\n","\n","        # 6. 누적 Gradient를 초기화 합니다.\n","        ##################################################\n","\n","        ##################################################\n","\n","        # Forward Propagation을 진행하여 결과를 얻습니다.\n","        output = model(**inputs)\n","\n","        # 손실함수에 output, label 값을 대입하여 손실을 계산합니다.\n","        loss = loss_fn(output, labels)\n","\n","        # 오차역전파(Back Propagation)을 진행하여 미분 값을 계산합니다.\n","        loss.backward()\n","\n","        # 계산된 Gradient를 업데이트 합니다.\n","        optimizer.step()\n","\n","        # 7. output의 max(dim=1)은 max probability와 max index를 반환합니다.\n","        # max probability는 무시하고, max index는 pred에 저장하여 label 값과 대조하여 정확도를 도출합니다.\n","        ################################################################\n","\n","        ################################################################\n","        # pred.eq(lbl).sum() 은 정확히 맞춘 label의 합계를 계산합니다. item()은 tensor에서 값을 추출합니다.\n","        # 합계는 corr 변수에 누적합니다.\n","        corr += index.eq(labels).sum().item()\n","        counts += len(labels)\n","\n","        # loss 값은 1개 배치의 평균 손실(loss) 입니다. labels.size(0)은 배치사이즈(batch size) 입니다.\n","        # loss 와 labels.size(0)를 곱하면 1개 배치의 전체 loss가 계산됩니다.\n","        # 이를 누적한 뒤 Epoch 종료시 전체 데이터셋의 개수로 나누어 평균 loss를 산출합니다.\n","        running_loss += loss.item() * labels.size(0)\n","\n","        # 프로그레스바에 학습 상황 업데이트\n","        prograss_bar.set_description(f\"training loss: {running_loss/(idx+1):.5f}, training accuracy: {corr / counts:.5f}\")\n","\n","\n","    # 누적된 정답수를 전체 개수로 나누어 주면 정확도가 산출됩니다.\n","    acc = corr / len(data_loader.dataset)\n","\n","    # 평균 손실(loss)과 정확도를 반환합니다.\n","    # train_loss, train_acc\n","    return running_loss / len(data_loader.dataset), acc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xAvQ9-DdZ3Uw"},"outputs":[],"source":["def model_evaluate(model, data_loader, loss_fn, device):\n","    # model.eval()은 모델을 평가모드로 설정을 바꾸어 줍니다.\n","    # 8. dropout과 같은 layer의 역할 변경을 위하여 evaluation 진행시 꼭 필요한 절차 입니다.\n","    ################################################################\n","\n","    ################################################################\n","\n","    # Gradient가 업데이트 되는 것을 방지 하기 위하여 반드시 필요합니다.\n","    with torch.no_grad():\n","        # loss와 accuracy 계산을 위한 임시 변수 입니다. 0으로 초기화합니다.\n","        corr = 0\n","        running_loss = 0\n","\n","        # 배치별 evaluation을 진행합니다.\n","        for inputs, labels in data_loader:\n","            # inputs, label 데이터를 device 에 올립니다. (cuda:0 혹은 cpu)\n","            inputs = {k:v.to(device) for k, v in inputs.items()}\n","            labels = labels.to(device)\n","\n","            # 모델에 Forward Propagation을 하여 결과를 도출합니다.\n","            output = model(**inputs)\n","\n","            # 9. output의 max(dim=1)은 max probability와 max index를 반환합니다.\n","            # max probability는 무시하고, max index는 pred에 저장하여 label 값과 대조하여 정확도를 도출합니다.\n","            ################################################################\n","\n","            ################################################################\n","\n","            # idx.eq(lbl).sum() 은 정확히 맞춘 label의 합계를 계산합니다. item()은 tensor에서 값을 추출합니다.\n","            # 합계는 corr 변수에 누적합니다.\n","            corr += torch.sum(index.eq(labels)).item()\n","\n","            # loss 값은 1개 배치의 평균 손실(loss) 입니다. img.size(0)은 배치사이즈(batch size) 입니다.\n","            # loss 와 img.size(0)를 곱하면 1개 배치의 전체 loss가 계산됩니다.\n","            # 이를 누적한 뒤 Epoch 종료시 전체 데이터셋의 개수로 나누어 평균 loss를 산출합니다.\n","            running_loss += loss_fn(output, labels).item() * labels.size(0)\n","\n","        # validation 정확도를 계산합니다.\n","        # 누적한 정답숫자를 전체 데이터셋의 숫자로 나누어 최종 accuracy를 산출합니다.\n","        acc = corr / len(data_loader.dataset)\n","\n","        # 결과를 반환합니다.\n","        # val_loss, val_acc\n","        return running_loss / len(data_loader.dataset), acc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"esBSUGDoatrC"},"outputs":[],"source":["# 최대 Epoch을 지정합니다.\n","num_epochs = 10\n","\n","# 10. checkpoint로 저장할 모델의 이름을 정의 합니다.\n","###########################################\n","\n","###########################################\n","\n","min_loss = np.inf\n","\n","# Epoch 별 훈련 및 검증을 수행합니다.\n","for epoch in range(num_epochs):\n","    # Model Training\n","    # 훈련 손실과 정확도를 반환 받습니다.\n","    train_loss, train_acc = model_train(albert_model, train_loader, loss_fn, optimizer, device)\n","\n","    # 검증 손실과 검증 정확도를 반환 받습니다.\n","    val_loss, val_acc = model_evaluate(albert_model, test_loader, loss_fn, device)\n","\n","    # 11. val_loss 가 개선되었다면 min_loss를 갱신하고 model의 가중치(weights)를 저장합니다.\n","    ###########################################################################\n","\n","\n","    ###########################################################################\n","\n","    # Epoch 별 결과를 출력합니다.\n","    print(f'epoch {epoch+1:02d}, loss: {train_loss:.5f}, acc: {train_acc:.5f}, val_loss: {val_loss:.5f}, val_accuracy: {val_acc:.5f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QLKFVTT4bE-Q"},"outputs":[],"source":["# 저장한 state_dict를 로드 합니다.\n","albert_model.load_state_dict(torch.load(f'{model_name}.pth'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fklSp01AbH0C"},"outputs":[],"source":["class Predictor():\n","    def __init__(self, model, tokenizer, labels: dict):\n","        self.model = model\n","        self.tokenizer = tokenizer\n","        self.labels = labels\n","\n","    def predict(self, sentence):\n","        # 토큰화 처리\n","        tokens = self.tokenizer(\n","            sentence,                # 1개 문장\n","            return_tensors='pt',     # 텐서로 반환\n","            truncation=True,         # 잘라내기 적용\n","            padding='max_length',    # 패딩 적용\n","            add_special_tokens=True  # 스페셜 토큰 적용\n","        )\n","        tokens.to(device)\n","        prediction = self.model(**tokens) # (1, 2)\n","\n","        prediction = F.softmax(prediction, dim=1) # (1,2)\n","\n","        output = prediction.argmax(dim=1).item()\n","\n","        prob, result = prediction.max(dim=1)[0].item(), self.labels[output]\n","        print(f'[{result}]\\n확률은: {prob*100:.3f}% 입니다.')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"73mtxPvtbJuS"},"outputs":[],"source":["# Huggingface 토크나이저 생성\n","tokenizer = BertTokenizerFast.from_pretrained(MODEL_NAME)\n","\n","labels = {\n","    0: '부정 리뷰 입니다.',\n","    1: '긍정 리뷰 입니다.'\n","}\n","\n","# Predictor 인스턴스를 생성합니다.\n","predictor = Predictor(BERT_model, tokenizer, labels)\n","\n","# 사용자 입력에 대하여 예측 후 출력을 낼 수 있는 간단한 함수를 생성합니다.\n","def predict_sentence(predictor):\n","    input_sentence = input('문장을 입력해 주세요: ')\n","    predictor.predict(input_sentence)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5pt05ejFbPT9"},"outputs":[],"source":["#12. 결과 확인 : 5문장에 대해서 실행하세요\n","###########################\n","predict_sentence(predictor)\n","###########################"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOayuXA8yB9iqWl0ezIE7AZ","collapsed_sections":["gQE_XOrqIMzn"],"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"03a51ba983f245afb62c6cb6cad3bf1b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0755151c65624a4dbe1dfd4f0fea1ec2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0acc3c745a4941b5bfde1e8c5ef12598":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2755c96989b44f02a277f13d8ca3a5aa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c6065877b2d24aa4be69434e6940f4d1","IPY_MODEL_c5c122b96a964f75b292a7c4c846a1bb","IPY_MODEL_8256f11e3ebe4ffe99c7478c82959caf"],"layout":"IPY_MODEL_608c7fc8742846bea2ee2be3d67fb0fb"}},"2f8c0edc0e144197940513688d95b5a6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4d66f1e0db8142fd9d96e2fbab2ea831","IPY_MODEL_b29958a593c74fbb8a489db535ce7cfa","IPY_MODEL_5b0f8d10ac194d33ac38284b2be7f00f"],"layout":"IPY_MODEL_daafbf7ffbb24384889c3c40027cd994"}},"39578fcb0c1f450eaa99943b360d8e6a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d9d6561332e4279b3ea6d45e1d536d5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"432a9751054e474d8c03e64cc0756c97":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_03a51ba983f245afb62c6cb6cad3bf1b","max":475782997,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b33721ae7fa54593a28df374199fb92a","value":475782997}},"45393735b8064898bd02c537edee21a4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"476ae4fcd59048129af937996868d493":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d66f1e0db8142fd9d96e2fbab2ea831":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea185c234c614b7a988a89a5ac4356a5","placeholder":"​","style":"IPY_MODEL_96bcffb94a234fb7bd65c4afd4562550","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"57f6af2ce575418da93bae66dd3ecd84":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a1b6cfcc41104b3a8b6464adcca4d728","placeholder":"​","style":"IPY_MODEL_e5297599bdb94a7996308cc4388ad954","value":" 476M/476M [00:02&lt;00:00, 242MB/s]"}},"5b0f8d10ac194d33ac38284b2be7f00f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_89a0ed78e3d54cb19d70cc56c886585b","placeholder":"​","style":"IPY_MODEL_f5dd37b591ba4825bc94fda343428d09","value":" 344k/344k [00:00&lt;00:00, 6.40MB/s]"}},"608c7fc8742846bea2ee2be3d67fb0fb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6189dfd8f4514862874c7f69a02766b4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a170b0fcbb0b45e5ae57974f66495bba","placeholder":"​","style":"IPY_MODEL_3d9d6561332e4279b3ea6d45e1d536d5","value":" 725/725 [00:00&lt;00:00, 40.0kB/s]"}},"65fca187c6ef4503a827b0ea6344cffa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_476ae4fcd59048129af937996868d493","placeholder":"​","style":"IPY_MODEL_90165400d18b49bfb1d800bd7f12ef39","value":"Downloading pytorch_model.bin: 100%"}},"78773b95a9c743669adcf6c25a951ef1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8101f1717afd47e6bc0615c1c4b66815":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8256f11e3ebe4ffe99c7478c82959caf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e761f89af59c41069781853b569e1989","placeholder":"​","style":"IPY_MODEL_fd558f05b5c247d58541ad63f76dfec5","value":" 80.0/80.0 [00:00&lt;00:00, 4.63kB/s]"}},"89a0ed78e3d54cb19d70cc56c886585b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90165400d18b49bfb1d800bd7f12ef39":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"96bcffb94a234fb7bd65c4afd4562550":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9ce0da6a8a9e40dba5521d8430753e43":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_39578fcb0c1f450eaa99943b360d8e6a","placeholder":"​","style":"IPY_MODEL_aa8eaef9fddb473b9c607c71da500c60","value":"Downloading (…)lve/main/config.json: 100%"}},"a170b0fcbb0b45e5ae57974f66495bba":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1b6cfcc41104b3a8b6464adcca4d728":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa8eaef9fddb473b9c607c71da500c60":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b19f6475a60c43b58bfe4713d9f98593":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0755151c65624a4dbe1dfd4f0fea1ec2","max":725,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f8b3047c9d884937841a1cb757f6e546","value":725}},"b29958a593c74fbb8a489db535ce7cfa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8101f1717afd47e6bc0615c1c4b66815","max":344259,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e53939fa329040408400bfe69890d78b","value":344259}},"b31da87ab7224eafa4a8ba62b9bd90ae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_65fca187c6ef4503a827b0ea6344cffa","IPY_MODEL_432a9751054e474d8c03e64cc0756c97","IPY_MODEL_57f6af2ce575418da93bae66dd3ecd84"],"layout":"IPY_MODEL_0acc3c745a4941b5bfde1e8c5ef12598"}},"b33721ae7fa54593a28df374199fb92a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b41805aca5b5458f9ac142e6ded57755":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5c122b96a964f75b292a7c4c846a1bb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b41805aca5b5458f9ac142e6ded57755","max":80,"min":0,"orientation":"horizontal","style":"IPY_MODEL_df218a22daa74c41b56a025f768ad809","value":80}},"c6065877b2d24aa4be69434e6940f4d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_78773b95a9c743669adcf6c25a951ef1","placeholder":"​","style":"IPY_MODEL_d9fb19fb79534b82ae4d03585b545126","value":"Downloading (…)okenizer_config.json: 100%"}},"ce5218fa7ff447008ae07b3aab7d8ae4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9ce0da6a8a9e40dba5521d8430753e43","IPY_MODEL_b19f6475a60c43b58bfe4713d9f98593","IPY_MODEL_6189dfd8f4514862874c7f69a02766b4"],"layout":"IPY_MODEL_45393735b8064898bd02c537edee21a4"}},"d9fb19fb79534b82ae4d03585b545126":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"daafbf7ffbb24384889c3c40027cd994":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df218a22daa74c41b56a025f768ad809":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e5297599bdb94a7996308cc4388ad954":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e53939fa329040408400bfe69890d78b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e761f89af59c41069781853b569e1989":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea185c234c614b7a988a89a5ac4356a5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5dd37b591ba4825bc94fda343428d09":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f8b3047c9d884937841a1cb757f6e546":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fd558f05b5c247d58541ad63f76dfec5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
